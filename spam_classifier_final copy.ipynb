{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "def load_dataset(name_url):\n",
    "    root_url = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "    url = root_url + name_url\n",
    "    tarball_path = Path(f\"email/{name_url.split('.')[0]}\")  # Directory to extract files\n",
    "    # Create root email directory if it doesn't exist\n",
    "    Path(\"email\").mkdir(parents=True, exist_ok=True)\n",
    "    # Download the tar file if it doesn't exist\n",
    "    if not tarball_path.is_file():\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as data_tarball:\n",
    "            data_tarball.extractall(path=\"email\")\n",
    "    # Return the path to the extracted directory containing emails\n",
    "\n",
    "# Datasets\n",
    "easy_ham = [\"20030228_easy_ham.tar.bz2\", \"20030228_easy_ham_2.tar.bz2\"]\n",
    "hard_ham = [\"20030228_hard_ham.tar.bz2\"]\n",
    "spam = [\"20030228_spam.tar.bz2\", \"20050311_spam_2.tar.bz2\"]\n",
    "\n",
    "for name_url in easy_ham+hard_ham+spam:\n",
    "    load_dataset(name_url)\n",
    "\n",
    "easy_ham_path = [f for f in sorted(Path(\"email/easy_ham\").iterdir()) if len(f.name) > 20] + [f for f in sorted(Path(\"email/easy_ham_2\").iterdir()) if len(f.name) > 20]\n",
    "hard_ham_path = [f for f in sorted(Path(\"email/hard_ham\").iterdir()) if len(f.name) > 20] \n",
    "spam_path = [f for f in sorted(Path(\"email/spam\").iterdir()) if len(f.name) > 20] + [f for f in sorted(Path(\"email/spam_2\").iterdir()) if len(f.name) > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n",
    "\n",
    "def load_email(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "\n",
    "easy_ham_emails = [load_email(f) for f in easy_ham_path]\n",
    "hard_ham_emails = [load_email(f) for f in hard_ham_path]\n",
    "spam_emails = [load_email(f) for f in spam_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n",
      "250\n",
      "1896\n"
     ]
    }
   ],
   "source": [
    "print(len(easy_ham_emails))\n",
    "print(len(hard_ham_emails))\n",
    "print(len(spam_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Martin A posted:\\nTassos Papadopoulos, the Greek sculptor behind the plan, judged that the\\n limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\\n Mount Athos monastic community, was ideal for the patriotic sculpture. \\n \\n As well as Alexander's granite features, 240 ft high and 170 ft wide, a\\n museum, a restored amphitheatre and car park for admiring crowds are\\nplanned\\n---------------------\\nSo is this mountain limestone or granite?\\nIf it's limestone, it'll weather pretty fast.\\n\\n------------------------ Yahoo! Groups Sponsor ---------------------~-->\\n4 DVDs Free +s&p Join Now\\nhttp://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\\n---------------------------------------------------------------------~->\\n\\nTo unsubscribe from this group, send an email to:\\nforteana-unsubscribe@egroups.com\\n\\n \\n\\nYour use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_ham_emails[1].get_content().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        multipart = \", \".join([get_email_structure(sub_email) for sub_email in payload])\n",
    "        return f\"multipart({multipart})\"\n",
    "    return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'text/plain': 96.17948717948681,\n",
       "         'multipart(text/plain, application/pgp-signature)': 2.5897435897435845,\n",
       "         'multipart(text/plain, text/html)': 0.512820512820513,\n",
       "         'multipart(text/plain, text/plain)': 0.10256410256410256,\n",
       "         'multipart(text/plain)': 0.07692307692307693,\n",
       "         'multipart(text/plain, application/ms-tnef, text/plain)': 0.05128205128205128,\n",
       "         'multipart(text/plain, application/octet-stream)': 0.05128205128205128,\n",
       "         'multipart(text/plain, multipart(text/plain))': 0.05128205128205128,\n",
       "         'multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)': 0.05128205128205128,\n",
       "         'text/html': 0.05128205128205128,\n",
       "         'multipart(text/plain, text/enriched)': 0.02564102564102564,\n",
       "         'multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)': 0.02564102564102564,\n",
       "         'multipart(text/plain, video/mng)': 0.02564102564102564,\n",
       "         'multipart(text/plain, application/x-pkcs7-signature)': 0.02564102564102564,\n",
       "         'multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))': 0.02564102564102564,\n",
       "         'multipart(text/plain, application/x-java-applet)': 0.02564102564102564,\n",
       "         'multipart(text/plain, application/x-patch)': 0.02564102564102564,\n",
       "         'multipart(multipart(text/plain, multipart(text/plain), text/plain), application/pgp-signature)': 0.02564102564102564,\n",
       "         'multipart(multipart(text/plain, text/html), image/jpeg, image/gif, image/gif, image/gif, image/gif)': 0.02564102564102564,\n",
       "         'multipart(text/plain, application/ms-tnef)': 0.02564102564102564,\n",
       "         'multipart(text/plain, text/plain, text/plain)': 0.02564102564102564})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails, len):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 100/len\n",
    "    return structures\n",
    "\n",
    "structures_counter(easy_ham_emails, 3900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'text/html': 47.199999999999896,\n",
       "         'text/plain': 32.39999999999995,\n",
       "         'multipart(text/plain, text/html)': 17.200000000000003,\n",
       "         'multipart(text/html)': 0.8,\n",
       "         'multipart(text/plain, image/bmp)': 0.4,\n",
       "         'multipart(multipart(text/plain, text/html))': 0.4,\n",
       "         'multipart(text/plain, application/x-pkcs7-signature)': 0.4,\n",
       "         'multipart(text/plain, image/png, image/png)': 0.4,\n",
       "         'multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/jpeg, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif)': 0.4,\n",
       "         'multipart(text/plain, text/plain)': 0.4})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(hard_ham_emails, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'text/plain': 42.985232067510005,\n",
       "         'text/html': 40.71729957805858,\n",
       "         'multipart(text/plain, text/html)': 8.386075949367074,\n",
       "         'multipart(text/html)': 2.5843881856540087,\n",
       "         'multipart(text/plain)': 2.3206751054852317,\n",
       "         'multipart(multipart(text/html))': 1.2130801687763713,\n",
       "         'multipart(multipart(text/plain, text/html))': 0.26371308016877637,\n",
       "         'multipart(text/plain, application/octet-stream)': 0.15822784810126583,\n",
       "         'multipart(text/html, text/plain)': 0.15822784810126583,\n",
       "         'multipart(text/plain, image/jpeg)': 0.15822784810126583,\n",
       "         'multipart(text/plain, application/octet-stream, text/plain)': 0.15822784810126583,\n",
       "         'multipart(text/html, application/octet-stream)': 0.10548523206751055,\n",
       "         'multipart/alternative': 0.10548523206751055,\n",
       "         'multipart(text/html, image/jpeg)': 0.10548523206751055,\n",
       "         'multipart(multipart(text/plain), application/octet-stream)': 0.10548523206751055,\n",
       "         'multipart(multipart(text/html), application/octet-stream, image/jpeg)': 0.052742616033755275,\n",
       "         'multipart(multipart(text/plain, text/html), image/gif)': 0.052742616033755275,\n",
       "         'multipart(text/plain, multipart(text/plain))': 0.052742616033755275,\n",
       "         'multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)': 0.052742616033755275,\n",
       "         'multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/gif)': 0.052742616033755275,\n",
       "         'text/plain charset=us-ascii': 0.052742616033755275,\n",
       "         'multipart(multipart(text/html), image/gif)': 0.052742616033755275,\n",
       "         'multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)': 0.052742616033755275,\n",
       "         'multipart(multipart(text/plain, text/html), image/gif, image/jpeg)': 0.052742616033755275})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails, 1896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spam have more html ones 53% while easy ham have just 0.51% but hard ham has 66% html. so of a email is a multipart or has a html content then it more probability of being a SPAM but if a email is php sihnatured it is more likely a ham email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 means Html present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <FreeSoftware-5265v80@yahoo.com>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id BE46143F9B\tfor <zzzz@localhost>; Mon, 26 Aug 2002 16:37:20 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Mon, 26 Aug 2002 21:37:20 +0100 (IST)\n",
      "Received : from yahoo.com ([211.185.47.189])\tby webnote.net (8.9.3/8.9.3) with SMTP id VAA27898\tfor <zzzz@spamassassin.taint.org>; Mon, 26 Aug 2002 21:39:06 +0100\n",
      "Reply-To : Free Publishing Software <FreeSoftware-5265v80@yahoo.com>\n",
      "Message-ID : <004b12e28d1a$4347d2b7$3ce68ab0@sgcrua>\n",
      "From : Free Publishing Software <FreeSoftware-5265v80@yahoo.com>\n",
      "To : zzzz@spamassassin.taint.org\n",
      "Subject : Take your Marketing to the Next Level\n",
      "Date : Mon, 26 Aug 2002 19:24:06 +0100\n",
      "MiME-Version : 1.0\n",
      "X-Priority : 3 (Normal)\n",
      "X-MSMail-Priority : Normal\n",
      "X-Mailer : Microsoft Outlook Express 5.00.2919.6700\n",
      "Importance : Normal\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[100].items():\n",
    "    print(header, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free Publishing Software <FreeSoftware-5265v80@yahoo.com>\n",
      "Take your Marketing to the Next Level\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[100][\"From\"])\n",
    "print(spam_emails[100][\"Subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(easy_ham_emails + spam_emails, dtype=\"object\")\n",
    "Y = np.array([0]*len(easy_ham_emails) + [1]*len(spam_emails))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_to_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    total_content = \"\"\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                content = part.get_content()\n",
    "            except:\n",
    "                content = str(part.get_payload())\n",
    "            if ctype == \"text/plain\":\n",
    "                total_content += content\n",
    "            else:\n",
    "                total_content += html_to_text(content)\n",
    "    return total_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details\n",
      "\n",
      "\n",
      "\n",
      "Want to refinance?\n",
      "\n",
      "Fill our this quick form and immediately have mortgage\n",
      "companies compete for you business. \n",
      "\n",
      "You will be offered the, absolute, BEST refinance rates \n",
      "availible!\n",
      "\n",
      "Your credit doesn't matter, don't even worry about past \n",
      "credit problems, we can refinance ANYONE!\n",
      "\n",
      "Let Us Put Our Expertise to Work for You!\n",
      "\n",
      "http://210.51.251.244/al/cgi-bin/redir.cgi?goto=ID74210\n",
      "\n",
      "Or Site 2\n",
      "http://61.129.81.99/al/cgi-bin/redir.cgi?goto=ID74215\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Erase\n",
      "http://210.51.251.244/al/uns/list.htm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(X_train[195]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fell\n",
      "fall\n",
      "fallen\n",
      "felt\n",
      "feel\n",
      "taken\n",
      "took\n",
      "take\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "for word in [\"fell\", \"fall\", \"fallen\", \"felt\", \"feel\", \"taken\", \"took\", \"taking\"]:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\huzai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'run', 'happiness', 'be']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [\"running\", \"ran\", \"runs\", \"run\", \"happiness\", \"was\"]\n",
    "lemmas = [lemmatizer.lemmatize(word, pos=\"v\") for word in words]  # pos=\"v\" for verbs\n",
    "\n",
    "print(lemmas)  # Output: ['run', 'run', 'run', 'run', 'happiness', 'be']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://210.51.251.244/al/cgi-bin/redir.cgi?goto=ID74210', 'http://61.129.81.99/al/cgi-bin/redir.cgi?goto=ID74215', 'http://210.51.251.244/al/uns/list.htm']\n"
     ]
    }
   ],
   "source": [
    "from urlextract import URLExtract\n",
    "def url_extractor(email):\n",
    "    url_extract = URLExtract()\n",
    "    urls = url_extract.find_urls(email)\n",
    "    return urls\n",
    "\n",
    "print(url_extractor(email_to_text(X_train[195])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import re\n",
    "\n",
    "class EmailtoWordCounterTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, strip_headers=True, to_lowercase=True, replace_numbers=True,\n",
    "                remove_punctuations=True, replace_urls=True, stemming=True):\n",
    "        self.strip_headers=strip_headers\n",
    "        self.to_lowercase=to_lowercase\n",
    "        self.replace_numbers=replace_numbers\n",
    "        self.replace_urls = replace_urls\n",
    "        self.remove_punctuations = remove_punctuations\n",
    "        self.stemming=stemming\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text=email_to_text(email) or \"\"\n",
    "            if self.to_lowercase:\n",
    "                text=text.lower()\n",
    "            if self.replace_urls:\n",
    "                if url_extractor is None:\n",
    "                    raise ValueError(\"URL extractor is not initialized!\")\n",
    "                urls = url_extractor(text)\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text=re.sub(\"\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+(?:\\.\\d*))?\", \"NUMBER\", text)\n",
    "            if self.remove_punctuations:\n",
    "                text=re.sub(\"\\W+\", ' ', text)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming:\n",
    "                if porter is None:\n",
    "                    raise ValueError(\"Porter Stemmer is not initialized!\")\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word_counts[lemmatizer.lemmatize(word, pos=\"v\")] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([Counter({'i': 9, 'of': 9, 'the': 9, 'your': 7, 'for': 7, 'this': 6, 'in': 5, 'a': 5, 'to': 5, 'you': 5, 'money': 5, 'my': 4, 'with': 4, 'on': 4, 'contact': 3, 'assistance': 3, 'mr': 3, 'jallow': 3, 'be': 3, 'and': 3, 'mail': 3, 'URL': 3, 'get': 2, 'search': 2, 'which': 2, 'transfer': 2, 'investement': 2, 'm': 2, 'ibrahim': 2, 'late': 2, 'unite': 2, 'u': 2, 'NUMBER': 2, 's': 2, 'realise': 2, 'can': 2, 'through': 2, 'e': 2, 'hello': 1, 'dear': 1, 'sir': 1, 'cause': 1, 'seriouse': 1, 'reliable': 1, 'foreign': 1, 'partner': 1, 'really': 1, 'make': 1, 'me': 1, 'purpose': 1, 'son': 1, 'sierraleonian': 1, 'business': 1, 'man': 1, 'kulu': 1, 'who': 1, 'die': 1, 'two': 1, 'yaers': 1, 'ago': 1, 'when': 1, 'revolutionary': 1, 'front': 1, 'rebel': 1, 'r': 1, 'f': 1, 'attack': 1, 'our': 1, 'residence': 1, 'makeni': 1, 'sierra': 1, 'leone': 1, 'follow': 1, 'cease': 1, 'fire': 1, 'agreement': 1, 'reach': 1, 'last': 1, 'year': 1, 'help': 1, 'nation': 1, 'peace': 1, 'keep': 1, 'troop': 1, 'use': 1, 'oppoturnity': 1, 'leave': 1, 'country': 1, 'very': 1, 'important': 1, 'document': 1, 'us': 1, 'NUMBERm': 1, 'fourteen': 1, 'million': 1, 'five': 1, 'hundred': 1, 'thounsand': 1, 'dollars': 1, 'deposit': 1, 'by': 1, 'father': 1, 'security': 1, 'company': 1, 'dakar': 1, 'senegal': 1, 'under': 1, 'name': 1, 'from': 1, 'diamond': 1, 'export': 1, 'now': 1, 'trust': 1, 'individual': 1, 'or': 1, 'foreing': 1, 'firm': 1, 'whom': 1, 'invest': 1, 'next': 1, 'kin': 1, 'these': 1, 'however': 1, 'base': 1, 'capability': 1, 'vast': 1, 'knowledge': 1, 'international': 1, 'commercial': 1, 'co': 1, 'opertion': 1, 'will': 1, 'give': 1, 'total': 1, 'sum': 1, 'after': 1, 'sucessfull': 1, 'please': 1, 'kindly': 1, 'communicate': 1, 'acceptance': 1, 'proposal': 1, 'address': 1, 'so': 1, 'that': 1, 'we': 1, 'discuss': 1, 'modalities': 1, 'see': 1, 'transaction': 1, 'count': 1, 'greately': 1, 'await': 1, 'earnest': 1, 'response': 1, 'regard': 1, 'yours': 1, 'faithfully': 1, '_____________________________________________________________________': 1, 'webdunia': 1, 'quiz': 1, 'contest': 1, 'limit': 1, 'time': 1, 'unlimited': 1, 'fun': 1, 'log': 1, 'win': 1, 'fabulous': 1, 'prize': 1, 'india': 1, 'first': 1, 'multilingual': 1, 'system': 1, 'free': 1, 'account': 1, 'at': 1}),\n",
      "       Counter({'NUMBER': 46, 'hextab': 21, 'i': 14, 'the': 10, 'c': 10, 'cNUMBER': 8, 'be': 7, 'in': 5, 'str': 5, 'if': 5, 's': 4, 'len': 4, 'decode': 4, 'on': 3, 'not': 3, 'to': 3, 'for': 3, 'and': 3, 'code': 3, 'hex': 3, 'substr': 3, 'my': 3, 'paul': 3, 'ie': 3, 'linux': 3, 'echo': 2, 'e': 2, 'f': 2, 'x': 2, 'why': 2, 'something': 2, 'it': 2, 'a': 2, 'get': 2, 'end': 2, 'check': 2, 'encode': 2, 'toupper': 2, 'footer': 2, 'mail': 2, 'yadda': 2, 'spam': 2, 'he': 2, 'jakma': 2, 'tue': 1, 'aug': 1, 'david': 1, 'neary': 1, 'write': 1, 'actually': 1, 'follow': 1, 'would': 1, 'some': 1, 'way': 1, 'sensible': 1, 'enc': 1, 'sed': 1, 'NUMBERa': 1, 'fa': 1, 'g': 1, 'no': 1, 'idea': 1, 'above': 1, 'along': 1, 'line': 1, 'attempt': 1, 'once': 1, 'realise': 1, 'straight': 1, 'swap': 1, 'but': 1, 'couldnt': 1, 'awk': 1, 'gensub': 1, 'insert': 1, 'anyway': 1, 'find': 1, 'internet': 1, 'adapt': 1, 'function': 1, 'decode_url': 1, 'dec': 1, 'lookup': 1, 'table': 1, 'b': 1, 'd': 1, 'length': 1, 'while': 1, 'usual': 1, 'start': 1, 'of': 1, 'uri': 1, 'char': 1, 'valid': 1, 'sprintf': 1, 'space': 1, 'apparently': 1, 'else': 1, 'return': 1, 'cheer': 1, 'dave': 1, 'ps': 1, 'late': 1, 'reply': 1, 'because': 1, 'original': 1, 'you': 1, 'receive': 1, 'this': 1, 'error': 1, 'catch': 1, 'filter': 1, 'up': 1, 'junkmail': 1, 'directory': 1, 'might': 1, 'have': 1, 'headers': 1, 'regard': 1, 'clubi': 1, 'org': 1, 'key': 1, 'id': 1, 'NUMBERaNUMBERffNUMBERa': 1, 'warn': 1, 'do': 1, 'ever': 1, 'send': 1, 'email': 1, 'dishone': 1, 'st': 1, 'fortune': 1, 'one': 1, 'nuclear': 1, 'bomb': 1, 'can': 1, 'ruin': 1, 'your': 1, 'whole': 1, 'day': 1, 'irish': 1, 'users': 1, 'group': 1, 'ilug': 1, 'URL': 1, 'un': 1, 'subscription': 1, 'information': 1, 'list': 1, 'maintainer': 1, 'listmaster': 1}),\n",
      "       Counter({'to': 6, 'the': 6, 'it': 5, 'sell': 4, 'do': 4, 'i': 4, 'book': 4, 'what': 3, 'be': 3, 'pratchett': 3, 'read': 3, 'and': 3, 'give': 3, 'when': 2, 'have': 2, 'of': 2, 'mr': 2, 'someone': 2, 'who': 2, 'then': 2, 'you': 1, 'try': 1, 'value': 1, 'example': 1, 'paper': 1, 'bind': 1, 'by': 1, 'glue': 1, 'or': 1, 'he': 1, 'stories': 1, 'question': 1, 'buy': 1, 'a': 1, 'purchase': 1, 'story': 1, 'any': 1, 'that': 1, 'revenue': 1, 'go': 1, 'if': 1, 'someones': 1, 'URL': 1, 'though': 1, 'with': 1, 'more': 1, 'succesfull': 1, 'pass': 1, 'each': 1, 'reader': 1, 'send': 1, 'money': 1, 'use': 1, 'bookstores': 1, 'recorstores': 1, 'etc': 1, 'destroy': 1, 'system': 1, 'record': 1, 'economy': 1, 'as': 1, 'resident': 1, 'sourpuss': 1, 'in': 1, 'germany': 1, 'bitter': 1, 'may': 1, 'better': 1, 'but': 1, 'here': 1, 'its': 1, 'just': 1, 'plain': 1, 'stinkin': 1, 'thinkin': 1, 'tom': 1}),\n",
      "       Counter({'NUMBER': 14, 'mit': 3, 'and': 3, 'the': 3, 'they': 3, 'i': 2, 'from': 2, 'original': 2, 'courseware': 2, 'at': 2, 'up': 2, 'useful': 2, 'b': 2, 'k': 2, 'delong': 2, 'bkdelong': 2, 'be': 2, 'to': 2, 'eugen': 2, 'leitl': 2, 'opencourseware': 2, 'll': 2, 'better': 1, 'late': 1, 'than': 1, 'never': 1, 'receive': 1, 'a': 1, 'grant': 1, 'project': 1, 'athena': 1, 's': 1, 'effort': 1, 'find': 1, 'end': 1, 'that': 1, 'hadn': 1, 't': 1, 'think': 1, 'much': 1, 'about': 1, 'distribution': 1, 'of': 1, 'instead': 1, 'have': 1, 'get': 1, 'wrap': 1, 'with': 1, 'x': 1, 'various': 1, 'unix': 1, 'tool': 1, 'other': 1, 'but': 1, 'not': 1, 'strictly': 1, 'educational': 1, 'efforts': 1, 'ken': 1, 'message': 1, 'mailto': 1, 'pobox': 1, 'com': 1, 'send': 1, 'tuesday': 1, 'october': 1, 'forkit': 1, 'subject': 1, 're': 1, 'pm': 1, 'write': 1, 'look': 1, 'hopefully': 1, 'put': 1, 'some': 1, 'more': 1, 'material': 1, 'soon': 1, 'URL': 1, 'sure': 1, 'keep': 1, 'everyone': 1, 'post': 1, 'on': 1, 'next': 1, 'update': 1, 'ceci': 1, 'edu': 1, 'cell': 1}),\n",
      "       Counter({'to': 7, 'of': 5, 'our': 5, 'free': 4, 'be': 4, 'for': 4, 'bonus': 3, 'quality': 3, 'from': 3, 'catalog': 3, 'you': 3, 'register': 3, 'now': 3, 'out': 3, 'linux': 3, 'offer': 2, 'we': 2, 'replicas': 2, 'goods': 2, 'all': 2, 'designer': 2, 'a': 2, 'the': 2, 'price': 2, 'receive': 2, 'information': 2, 'email': 2, 'fastnetspain': 2, 'net': 2, 'sure': 2, 'don': 2, 't': 2, 'miss': 2, 'ie': 2, 'see': 1, 'below': 1, 'can': 1, 'supply': 1, 'top': 1, 'virtually': 1, 'identical': 1, 'just': 1, 'about': 1, 'anything': 1, 'watch': 1, 'wallets': 1, 'lighter': 1, 'lingerie': 1, 'clothe': 1, 'accessories': 1, 'even': 1, 'electrical': 1, 'your': 1, 'favorite': 1, 'label': 1, 'reproduce': 1, 'at': 1, 'fraction': 1, 'major': 1, 'credit': 1, 'card': 1, 'accept': 1, 'worldwide': 1, 'certify': 1, 'ship': 1, 'guarantee': 1, 'currently': 1, 'build': 1, 'so': 1, 'let': 1, 'us': 1, 'know': 1, 'that': 1, 'want': 1, 'notification': 1, 'when': 1, 'on': 1, 'line': 1, 'publish': 1, 'later': 1, 'this': 1, 'month': 1, 'qualify': 1, 'great': 1, 'and': 1, 'one': 1, 'pair': 1, 'replica': 1, 'sunglasses': 1, 'regular': 1, 'NUMBER': 1, 'check': 1, 'charge': 1, 'more': 1, 'remove': 1, 'future': 1, 'mail': 1, 'noreplicas': 1, 'irish': 1, 'users': 1, 'group': 1, 'ilug': 1, 'URL': 1, 'un': 1, 'subscription': 1, 'list': 1, 'maintainer': 1, 'listmaster': 1})],\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(EmailtoWordCounterTransformer().fit_transform(X_train[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCountertoVectorsTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        total_words = Counter()\n",
    "        for words_counter in X:\n",
    "            for word, count in words_counter.items():\n",
    "                total_words[word] += min(count, 10)\n",
    "        most_common = total_words.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word:index+1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        vector = []\n",
    "        col_index = []\n",
    "        row_index = []\n",
    "        for row, email_word_counter in enumerate(X):\n",
    "            for word, count in email_word_counter.items():\n",
    "                row_index.append(row)\n",
    "                col_index.append(self.vocabulary_.get(word, 0))\n",
    "                vector.append(count)\n",
    "        return csr_matrix((vector, (row_index, col_index)), shape=(len(X), self.vocabulary_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x11 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 49 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TovectorTransformer = WordCountertoVectorsTransformer(vocabulary_size=10)\n",
    "sample_vector = TovectorTransformer.fit_transform(\n",
    "    EmailtoWordCounterTransformer().fit_transform(X_train[:5]))\n",
    "sample_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[222,   9,   9,   5,   2,   3,   9,   7,   3,   5,   5],\n",
       "       [230,  10,  14,   3,  46,   7,   1,   3,   3,   5,   2],\n",
       "       [ 95,   6,   4,   6,   0,   3,   2,   0,   3,   1,   1],\n",
       "       [ 99,   3,   2,   2,  14,   2,   1,   0,   3,   0,   1],\n",
       "       [142,   2,   0,   7,   1,   4,   5,   4,   1,   0,   2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'to': 3,\n",
       " 'NUMBER': 4,\n",
       " 'be': 5,\n",
       " 'of': 6,\n",
       " 'for': 7,\n",
       " 'and': 8,\n",
       " 'in': 9,\n",
       " 'a': 10}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TovectorTransformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessing = Pipeline([\n",
    "    (\"Words_to_Counter\", EmailtoWordCounterTransformer()),\n",
    "    (\"WordCounter_To_Vector\", WordCountertoVectorsTransformer())\n",
    "])\n",
    "X_train_processed = preprocessing.fit_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801754956126096"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "train_predict_log = cross_val_predict(log_clf, X_train_processed, Y_train, cv=10)\n",
    "f1_score(Y_train, train_predict_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749670619235836"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "train_predict_rnd = cross_val_predict(rnd_clf, X_train_tfidf, Y_train, cv=10)\n",
    "f1_score(Y_train, train_predict_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836387434554974"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(random_state=42)\n",
    "train_predict_svm = cross_val_predict(svm_clf, X_train_tfidf, Y_train, cv=10)\n",
    "f1_score(Y_train, train_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 98.03%\n",
      "Recall 98.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[797,   7],\n",
       "       [  7, 349]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed = preprocessing.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_processed)\n",
    "log_clf.fit(X_train_processed, Y_train)\n",
    "Y_pred = log_clf.predict(X_test_processed)\n",
    "print(f\"Precision {precision_score(Y_test, Y_pred):.2%}\")\n",
    "print(f\"Recall {recall_score(Y_test, Y_pred):.2%}\")\n",
    "conf = confusion_matrix(Y_test, Y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142, 108],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham_processed = preprocessing.transform(np.array(hard_ham_emails, dtype=\"object\"))\n",
    "hard_ham_predict = log_clf.predict(hard_ham_processed)\n",
    "Y_orig = np.array([0]*len(hard_ham_emails))\n",
    "conf1 = confusion_matrix(Y_orig, hard_ham_predict)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 99.14%\n",
      "Recall 96.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[801,   3],\n",
       "       [ 11, 345]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rnd_clf.fit(X_train_tfidf, Y_train)\n",
    "Y_pred = rnd_clf.predict(X_test_tfidf)\n",
    "print(f\"Precision {precision_score(Y_test, Y_pred):.2%}\")\n",
    "print(f\"Recall {recall_score(Y_test, Y_pred):.2%}\")\n",
    "conf = confusion_matrix(Y_test, Y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118, 132],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham_tfidf = tfidf_transformer.fit_transform(hard_ham_processed)\n",
    "hard_ham_predict = rnd_clf.predict(hard_ham_tfidf)\n",
    "Y_orig = np.array([0]*len(hard_ham_emails))\n",
    "conf1 = confusion_matrix(Y_orig, hard_ham_predict)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 98.05%\n",
      "Recall 98.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[797,   7],\n",
       "       [  4, 352]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_clf.fit(X_train_tfidf, Y_train)\n",
    "Y_pred = svm_clf.predict(X_test_tfidf)\n",
    "print(f\"Precision {precision_score(Y_test, Y_pred):.2%}\")\n",
    "print(f\"Recall {recall_score(Y_test, Y_pred):.2%}\")\n",
    "conf = confusion_matrix(Y_test, Y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148, 102],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham_predict = svm_clf.predict(hard_ham_tfidf)\n",
    "Y_orig = np.array([0]*len(hard_ham_emails))\n",
    "conf1 = confusion_matrix(Y_orig, hard_ham_predict)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this only three models were selected logistic regression, random forest, and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best parameters: {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'max_depth': [30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['log2'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rnd_search_rf = RandomizedSearchCV(rnd_clf, param_grid,n_iter=5, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
    "rnd_search_rf.fit(X_train_tfidf, Y_train)\n",
    "print(\"Best parameters:\", rnd_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.021981</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.368331</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>30</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'n_estimators': 1000, 'min_samples_split': 10...</td>\n",
       "      <td>0.978304</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.968379</td>\n",
       "      <td>0.975331</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.305813</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.225820</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>30</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "      <td>0.976331</td>\n",
       "      <td>0.977295</td>\n",
       "      <td>0.968442</td>\n",
       "      <td>0.974023</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.458741</td>\n",
       "      <td>0.035268</td>\n",
       "      <td>0.220125</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>40</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.975418</td>\n",
       "      <td>0.976331</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.973736</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.245205</td>\n",
       "      <td>0.063456</td>\n",
       "      <td>0.340669</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>40</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'n_estimators': 1000, 'min_samples_split': 5,...</td>\n",
       "      <td>0.973346</td>\n",
       "      <td>0.974257</td>\n",
       "      <td>0.973241</td>\n",
       "      <td>0.973615</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.535883</td>\n",
       "      <td>0.127338</td>\n",
       "      <td>0.281497</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>40</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'n_estimators': 1000, 'min_samples_split': 2,...</td>\n",
       "      <td>0.974206</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.969154</td>\n",
       "      <td>0.971861</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      10.021981      0.014521         0.368331        0.016084   \n",
       "3       5.305813      0.016612         0.225820        0.005199   \n",
       "4       5.458741      0.035268         0.220125        0.002983   \n",
       "1      11.245205      0.063456         0.340669        0.014947   \n",
       "2      12.535883      0.127338         0.281497        0.006166   \n",
       "\n",
       "   param_n_estimators  param_min_samples_split  param_min_samples_leaf  \\\n",
       "0                1000                       10                       1   \n",
       "3                 500                       10                       1   \n",
       "4                 500                        2                       2   \n",
       "1                1000                        5                       1   \n",
       "2                1000                        2                       1   \n",
       "\n",
       "  param_max_features  param_max_depth param_class_weight  \\\n",
       "0               log2               30           balanced   \n",
       "3               log2               30           balanced   \n",
       "4               log2               40           balanced   \n",
       "1               log2               40           balanced   \n",
       "2               log2               40           balanced   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'n_estimators': 1000, 'min_samples_split': 10...           0.978304   \n",
       "3  {'n_estimators': 500, 'min_samples_split': 10,...           0.976331   \n",
       "4  {'n_estimators': 500, 'min_samples_split': 2, ...           0.975418   \n",
       "1  {'n_estimators': 1000, 'min_samples_split': 5,...           0.973346   \n",
       "2  {'n_estimators': 1000, 'min_samples_split': 2,...           0.974206   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.979310           0.968379         0.975331        0.004933   \n",
       "3           0.977295           0.968442         0.974023        0.003966   \n",
       "4           0.976331           0.969458         0.973736        0.003048   \n",
       "1           0.974257           0.973241         0.973615        0.000456   \n",
       "2           0.972222           0.969154         0.971861        0.002078   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "3                2  \n",
       "4                3  \n",
       "1                4  \n",
       "2                5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(rnd_search_rf.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rnd_search_log = RandomizedSearchCV(log_clf, param_grid, n_iter=10, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
    "rnd_search_log.fit(X_train_processed, Y_train)\n",
    "print(\"Best parameters:\", rnd_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.879749</td>\n",
       "      <td>0.111129</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'class_we...</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.984466</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978145</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.921679</td>\n",
       "      <td>0.112914</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1.00</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'class_we...</td>\n",
       "      <td>0.975752</td>\n",
       "      <td>0.980658</td>\n",
       "      <td>0.969756</td>\n",
       "      <td>0.975388</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.259124</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'clas...</td>\n",
       "      <td>0.968191</td>\n",
       "      <td>0.973399</td>\n",
       "      <td>0.973241</td>\n",
       "      <td>0.971610</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.551338</td>\n",
       "      <td>0.153869</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>100.00</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'clas...</td>\n",
       "      <td>0.964043</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.962745</td>\n",
       "      <td>0.965962</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462221</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'clas...</td>\n",
       "      <td>0.966403</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>0.959285</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.642334</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'class_we...</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.965449</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.960533</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.550115</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'class_we...</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>0.945309</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.395379</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l2', 'class_wei...</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.892996</td>\n",
       "      <td>0.912176</td>\n",
       "      <td>0.903513</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.247817</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l2', 'class_wei...</td>\n",
       "      <td>0.898897</td>\n",
       "      <td>0.881976</td>\n",
       "      <td>0.893458</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.130753</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100.00</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l2', 'class_wei...</td>\n",
       "      <td>0.898897</td>\n",
       "      <td>0.881976</td>\n",
       "      <td>0.893458</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_solver  \\\n",
       "6       0.879749      0.111129         0.003845        0.000216        lbfgs   \n",
       "7       0.921679      0.112914         0.004196        0.000944        lbfgs   \n",
       "4       0.676764      0.259124         0.004691        0.000494    liblinear   \n",
       "0       3.551338      0.153869         0.003829        0.000635    liblinear   \n",
       "3       0.462221      0.059176         0.004357        0.000250    liblinear   \n",
       "2       0.642334      0.122594         0.004690        0.001446        lbfgs   \n",
       "8       0.550115      0.073992         0.004178        0.000605        lbfgs   \n",
       "9       3.395379      0.040762         0.001673        0.000230         saga   \n",
       "1       4.247817      0.007601         0.003664        0.000472         saga   \n",
       "5       4.130753      0.087467         0.003824        0.000247         saga   \n",
       "\n",
       "  param_penalty param_class_weight  param_C  \\\n",
       "6            l2               None     1.00   \n",
       "7            l2           balanced     1.00   \n",
       "4            l2               None     0.10   \n",
       "0            l2               None   100.00   \n",
       "3            l2           balanced     0.01   \n",
       "2            l2           balanced     0.01   \n",
       "8            l2               None     0.01   \n",
       "9            l2               None     0.01   \n",
       "1            l2           balanced     0.10   \n",
       "5            l2           balanced   100.00   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "6  {'solver': 'lbfgs', 'penalty': 'l2', 'class_we...           0.975610   \n",
       "7  {'solver': 'lbfgs', 'penalty': 'l2', 'class_we...           0.975752   \n",
       "4  {'solver': 'liblinear', 'penalty': 'l2', 'clas...           0.968191   \n",
       "0  {'solver': 'liblinear', 'penalty': 'l2', 'clas...           0.964043   \n",
       "3  {'solver': 'liblinear', 'penalty': 'l2', 'clas...           0.966403   \n",
       "2  {'solver': 'lbfgs', 'penalty': 'l2', 'class_we...           0.955912   \n",
       "8  {'solver': 'lbfgs', 'penalty': 'l2', 'class_we...           0.938525   \n",
       "9  {'solver': 'saga', 'penalty': 'l2', 'class_wei...           0.905366   \n",
       "1  {'solver': 'saga', 'penalty': 'l2', 'class_wei...           0.898897   \n",
       "5  {'solver': 'saga', 'penalty': 'l2', 'class_wei...           0.898897   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "6           0.984466           0.974359         0.978145        0.004499   \n",
       "7           0.980658           0.969756         0.975388        0.004458   \n",
       "4           0.973399           0.973241         0.971610        0.002419   \n",
       "0           0.971098           0.962745         0.965962        0.003670   \n",
       "3           0.965653           0.959285         0.963780        0.003193   \n",
       "2           0.965449           0.960239         0.960533        0.003899   \n",
       "8           0.950355           0.947047         0.945309        0.004984   \n",
       "9           0.892996           0.912176         0.903513        0.007939   \n",
       "1           0.881976           0.893458         0.891444        0.007053   \n",
       "5           0.881976           0.893458         0.891444        0.007053   \n",
       "\n",
       "   rank_test_score  \n",
       "6                1  \n",
       "7                2  \n",
       "4                3  \n",
       "0                4  \n",
       "3                5  \n",
       "2                6  \n",
       "8                7  \n",
       "9                8  \n",
       "1                9  \n",
       "5                9  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(rnd_search_log.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best parameters: {'max_iter': 5000, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 5, 'class_weight': 'balanced', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 2000],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 1e-3, 1e-2, 0.1, 1],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [1000, 5000, 10000, 15000, 20000],\n",
    "    'degree': [2, 3, 4, 5]\n",
    "}\n",
    "rnd_search_svc = RandomizedSearchCV(svc, param_grid, n_iter=100, cv=3, scoring='f1', verbose=2, n_jobs=-1)\n",
    "rnd_search_svc.fit(X_train_tfidf, Y_train)\n",
    "print(\"Best parameters:\", rnd_search_svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.361630</td>\n",
       "      <td>0.097463</td>\n",
       "      <td>1.144800</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>5000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'max_iter': 5000, 'kernel': 'rbf', 'gamma': '...</td>\n",
       "      <td>0.984405</td>\n",
       "      <td>0.985394</td>\n",
       "      <td>0.981427</td>\n",
       "      <td>0.983742</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.119153</td>\n",
       "      <td>0.070144</td>\n",
       "      <td>1.068561</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>5000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'max_iter': 5000, 'kernel': 'rbf', 'gamma': 1...</td>\n",
       "      <td>0.983415</td>\n",
       "      <td>0.985394</td>\n",
       "      <td>0.981427</td>\n",
       "      <td>0.983412</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.873128</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>0.902618</td>\n",
       "      <td>0.033963</td>\n",
       "      <td>5000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'max_iter': 5000, 'kernel': 'rbf', 'gamma': '...</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>0.980431</td>\n",
       "      <td>0.983390</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.054260</td>\n",
       "      <td>0.121694</td>\n",
       "      <td>0.981956</td>\n",
       "      <td>0.064817</td>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>4</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'max_iter': 1000, 'kernel': 'rbf', 'gamma': '...</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.985394</td>\n",
       "      <td>0.980431</td>\n",
       "      <td>0.983091</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.607342</td>\n",
       "      <td>0.022722</td>\n",
       "      <td>0.779947</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>{'max_iter': 1000, 'kernel': 'rbf', 'gamma': '...</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.985394</td>\n",
       "      <td>0.980431</td>\n",
       "      <td>0.983091</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "74       2.361630      0.097463         1.144800        0.025150   \n",
       "32       2.119153      0.070144         1.068561        0.020954   \n",
       "14       1.873128      0.079193         0.902618        0.033963   \n",
       "73       2.054260      0.121694         0.981956        0.064817   \n",
       "2        1.607342      0.022722         0.779947        0.012262   \n",
       "\n",
       "    param_max_iter param_kernel param_gamma  param_degree param_class_weight  \\\n",
       "74            5000          rbf       scale             5           balanced   \n",
       "32            5000          rbf           1             2           balanced   \n",
       "14            5000          rbf       scale             5               None   \n",
       "73            1000          rbf       scale             4           balanced   \n",
       "2             1000          rbf       scale             2               None   \n",
       "\n",
       "    param_C                                             params  \\\n",
       "74     10.0  {'max_iter': 5000, 'kernel': 'rbf', 'gamma': '...   \n",
       "32     10.0  {'max_iter': 5000, 'kernel': 'rbf', 'gamma': 1...   \n",
       "14     10.0  {'max_iter': 5000, 'kernel': 'rbf', 'gamma': '...   \n",
       "73    100.0  {'max_iter': 1000, 'kernel': 'rbf', 'gamma': '...   \n",
       "2    2000.0  {'max_iter': 1000, 'kernel': 'rbf', 'gamma': '...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "74           0.984405           0.985394           0.981427         0.983742   \n",
       "32           0.983415           0.985394           0.981427         0.983412   \n",
       "14           0.984375           0.985366           0.980431         0.983390   \n",
       "73           0.983447           0.985394           0.980431         0.983091   \n",
       "2            0.983447           0.985394           0.980431         0.983091   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "74        0.001686                1  \n",
       "32        0.001620                2  \n",
       "14        0.002132                3  \n",
       "73        0.002042                4  \n",
       "2         0.002042                4  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(rnd_search_svc.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rnd_search_svc.best_params_\n",
    "svm_clf = SVC(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 97.78%\n",
      "Recall 99.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[796,   8],\n",
       "       [  3, 353]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_clf.fit(X_train_tfidf, Y_train)\n",
    "Y_pred = svm_clf.predict(X_test_tfidf)\n",
    "print(f\"Precision {precision_score(Y_test, Y_pred):.2%}\")\n",
    "print(f\"Recall {recall_score(Y_test, Y_pred):.2%}\")\n",
    "conf = confusion_matrix(Y_test, Y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149, 101],\n",
       "       [  0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham_predict = svm_clf.predict(hard_ham_tfidf)\n",
    "Y_orig = np.array([0]*len(hard_ham_emails))\n",
    "conf1 = confusion_matrix(Y_orig, hard_ham_predict)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah model with most recall is select SVC model works best for this email classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email_classifier_model.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_clf, \"email_classifier_model.pkl\")"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
